# Text-Summarization-SOTA-Experiment
An experiment of the state of the art in single (for short document and long document) and multi-document summarization models.

  This repository was set-up for the consultation of the experimented pretained Transformer-based abstractive text summarization models, and the metrics (such as, ROUGE (ROUGE-1, ROUG-2, ROUGE-3, ROUGE-L), CHRF, METEOR, and BertScore) used to evalauted these models, an also the factual consistency check of the model's generated summary.

The Script directory contains various folder of the ipython file for runing the experiment and an Automatic-Evaluation folder containing the various metrics. 

Training-Parameters folder contains the parameters used in training or fine-tuneing each experimented model.

The Summary folder contain the out generated by each model. While the Metrics-Score folder contain the result of the evaluation on each model's output summary. 
