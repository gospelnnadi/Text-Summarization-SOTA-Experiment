<!--- README file for Text-Summarization-SOTA-Experiment --->
# Text-Summarization-SOTA-Experiment
An experiment of the state of the art in single (for short document and long document) and multi-document summarization models. The link to the [paper] (https://arxiv.org/abs/2412.17165)

  This repository was set-up for the consultation of the experimented pretained Transformer-based abstractive text summarization models, and the metrics (such as, ROUGE (ROUGE-1, ROUG-2, ROUGE-3, ROUGE-L), CHRF, METEOR, and BertScore) used to evalauted these models, an also the factual consistency check of the model's generated summary.

The Script directory contains various folder of the ipython file for runing the experiment and an Automatic-Evaluation folder containing the various metrics. 

Training-Parameters folder contains the parameters used in training or fine-tuneing each experimented model.

The Summary folder contain the out generated by each model. While the Metrics-Score folder contain the result of the evaluation on each model's output summary. 

####
If you find our work useful, please consider citingï¼š
```bash
@misc{nnadi2024surveyabstractivetextsummarization,
      title={Survey on Abstractive Text Summarization: Dataset, Models, and Metrics}, 
      author={Gospel Ozioma Nnadi and Flavio Bertini},
      year={2024},
      eprint={2412.17165},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.17165}, 
}
```